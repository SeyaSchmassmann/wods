{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPI9Fj_Pes3L"
      },
      "source": [
        "# Original CvT-Model\n",
        "\n",
        "<img src=\"./../CvT-Original.drawio.png?raw=1\" alt=\"CvT-Modell mit Convolutional Embedding\" title=\"CvT-Modell mit Convolutional Embedding\" height=\"400\" />\n",
        "\n",
        "Dimensions sind ohne Batch-Size.\n",
        "\n",
        "## Input-Dimensions\n",
        "\n",
        "**Dimensions:** $H_0 = 64px, \\quad W_0 = 64px, \\quad C_0 = 3$ \\\n",
        "**Output-Shape:** `(3, 64, 64)`\n",
        "\n",
        "## Conv2d\n",
        "\n",
        "Berechnung Output-Dimensions:\n",
        "\n",
        "$ \\text{kernel size}\\ k = 7, \\quad \\text{stride}\\ s = 4, \\quad \\text{padding}\\ p = 3 $ \\\n",
        "$ H_i = \\frac{H_{i-1} + 2p - k}{s}\\ + 1, \\quad W_i = \\frac{W_{i-1} + 2p - k}{s}\\ + 1 $\n",
        "\n",
        "**Output-Dimensions:** $H_1 = 16px, \\quad W_1 = 16px, \\quad C_1 = 64$ \\\n",
        "**Output-Shape:** `(64, 16, 16)`\n",
        "\n",
        "## Flatten\n",
        "\n",
        "**Output-Dimensions:** $H_1 W_1 \\times C_1 = 16*16 \\times 64$ \\\n",
        "**Output-Shape:** `(256, 64)`\n",
        "\n",
        "## Multi-Head Attention\n",
        "\n",
        "Berechnung der Query-, Key- und Value-Matrizen:\n",
        "\n",
        "$X \\in \\mathbb{R}^{H_1 W_1 \\times C_1}$ \\\n",
        "$d_k$ ist die Dimension der Value-, Query- und Key-Vektoren \\\n",
        "$W^Q, W^K, W^V \\in \\mathbb{R}^{C_1 \\times d_k}$ \\\n",
        "$Q = XW^Q, \\quad K = XW^K, \\quad V = XW^V$\n",
        "\n",
        "$d_k = 64$ \\\n",
        "$Q, K, V \\in \\mathbb{R}^{256 \\times 64}$\n",
        "\n",
        "**Output-Dimensions:** $256 \\times 64$ \\\n",
        "**Output-Shape:** `(256, 64)`\n",
        "\n",
        "## MLP\n",
        "\n",
        "Expansion factor: $e = 4$\n",
        "\n",
        "1. **Step:** Linear ➔ GELU ➔ Dropout\n",
        "   \n",
        "   **Output-Dimensions:** $256 \\times 64 \\times 4 = 256 \\times 256$ \\\n",
        "   **Output-Shape:** `(256, 256)`\n",
        "\n",
        "2. **Step:** Linear ➔ Dropout\n",
        "\n",
        "    **Output-Dimensions:** $256 \\times 256 \\times 64 = 256 \\times 64$ \\\n",
        "    **Output-Shape:** `(256, 64)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ul2uMlQes3O"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nIi1ayzAfHT0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.1.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/lib/python3/dist-packages (from pytorch-lightning) (5.4.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (69.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2020.6.20)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/lib/python3/dist-packages (from lightning) (5.4.1)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2023.6.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.14.3)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (23.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.1.1+cu121)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.7.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.9.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (69.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.1.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (2020.6.20)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pytorch-lightning\n",
        "%pip install lightning\n",
        "%pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dq96M21xes3O"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import lightning as L\n",
        "from einops import rearrange\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.classification import Accuracy\n",
        "from pathlib import Path\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjIjjCP2es3Q"
      },
      "source": [
        "# Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s7wK3pcies3Q"
      },
      "outputs": [],
      "source": [
        "class EmbeddingBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels=3,\n",
        "                 embed_dim=64,\n",
        "                 patch_size=7,\n",
        "                 stride=4,\n",
        "                 padding=3,\n",
        "                 norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Conv2d(\n",
        "            in_channels, embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            stride=stride,\n",
        "            padding=padding\n",
        "        )\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
        "        x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvProjection(nn.Module):\n",
        "    def __init__(self, embed_dim, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Conv2d(embed_dim, embed_dim, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, groups=embed_dim)\n",
        "        self.pointwise = nn.Conv2d(embed_dim, embed_dim, kernel_size=1)\n",
        "        self.norm = nn.BatchNorm2d(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        H = W = int(N**0.5)\n",
        "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
        "        x = self.proj(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.norm(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim=64,\n",
        "                 num_heads=1,\n",
        "                 mlp_ratio=4.0,\n",
        "                 drop=0.1,\n",
        "                 norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.conv_proj = ConvProjection(embed_dim)\n",
        "        self.norm1 = norm_layer(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=drop, batch_first=True)\n",
        "\n",
        "        self.norm2 = norm_layer(embed_dim)\n",
        "        hidden_dim = int(embed_dim * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(hidden_dim, embed_dim),\n",
        "            nn.Dropout(drop)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_proj = self.conv_proj(x)\n",
        "        x = x + self.attn(self.norm1(x_proj), self.norm1(x_proj), self.norm1(x_proj))[0]\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szfPHjFFes3Q"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dy847tS2es3Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape is as expected: torch.Size([2, 256, 64])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(2, 3, 64, 64)\n",
        "excepted_output_shape = (2, 256, 64)\n",
        "\n",
        "embedding_block = EmbeddingBlock()\n",
        "transformer_block = TransformerBlock()\n",
        "\n",
        "output = embedding_block(input)\n",
        "output = transformer_block(output)\n",
        "\n",
        "assert output.shape == excepted_output_shape, f\"Expected shape {excepted_output_shape}, but got {output.shape}\"\n",
        "print(\"Output shape is as expected:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa41nXqUes3Q"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hUFVhRXUes3R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data already extracted.\n",
            "Processing validation set...\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 30] Read-only file system: '/datasets/tiny-imagenet-200/tiny-imagenet-200'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessData\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare_data_and_get_loaders\n\u001b[0;32m----> 3\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_and_get_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datasets/tiny-imagenet-200\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/notebooks/models/processData.py:108\u001b[0m, in \u001b[0;36mprepare_data_and_get_loaders\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    105\u001b[0m dir_val_annotations \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_data_val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_annotations.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m dir_data_val_processed \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[43marrange_validation_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_val_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_val_annotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_data_val_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_tiny_imagenet_loaders(dir_data_train,\n\u001b[1;32m    111\u001b[0m                                  dir_data_val_processed,\n\u001b[1;32m    112\u001b[0m                                  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m                                  val_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m    116\u001b[0m                                  seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
            "File \u001b[0;32m/notebooks/models/processData.py:25\u001b[0m, in \u001b[0;36marrange_validation_set\u001b[0;34m(val_images_dir, val_annotations_file, val_processed_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(val_processed_dir):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing validation set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_processed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(val_annotations_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     28\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n",
            "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/datasets/tiny-imagenet-200/tiny-imagenet-200'"
          ]
        }
      ],
      "source": [
        "from models.processData import prepare_data_and_get_loaders\n",
        "\n",
        "train_loader, val_loader, test_loader = prepare_data_and_get_loaders(\"/datasets/tiny-imagenet-200/tiny-imagenet-200.zip\", \"/datasets/tiny-imagenet-200/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1d7soVVes3S"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D5wTcwres3S"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "image, label = train_loader.dataset[0]\n",
        "imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzpsw2Yues3T"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A8o7685es3T"
      },
      "outputs": [],
      "source": [
        "class CvTSimplifiedEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels=3,\n",
        "                 num_classes=200,\n",
        "                 embed_dim=64,\n",
        "                 depth=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.embedding = EmbeddingBlock(\n",
        "            in_channels=in_channels,\n",
        "            embed_dim=embed_dim,\n",
        "            stride=4,\n",
        "            padding=3,\n",
        "            norm_layer=nn.LayerNorm\n",
        "        )\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential(*[\n",
        "            nn.Sequential(TransformerBlock(), EmbeddingBlock()) for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            nn.Flatten(1),\n",
        "            nn.Linear(embed_dim, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR_jkON4es3T"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6f5bEphes3U"
      },
      "outputs": [],
      "source": [
        "model = CvTSimplifiedEmbedding()\n",
        "dummy_input = torch.randn(8, 3, 64, 64)\n",
        "output = model(dummy_input)\n",
        "\n",
        "assert output.shape == (8, 200), f\"Expected output shape (8, 200), but got {output.shape}\"\n",
        "print(\"Model output shape is as expected:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ssdD8E3es3U"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gfnKuY4es3U"
      },
      "outputs": [],
      "source": [
        "from models.trainModel import train_test_model\n",
        "\n",
        "train_test_model(model, train_loader, val_loader, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
